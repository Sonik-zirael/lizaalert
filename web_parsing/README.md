## Парсинг данных

Для парсинга данных с форума https://lizaalert.org/ используется язык программирования python (не ниже 3.8) и библиотека Scrapy.

### Запуск

1. Настроить виртуальное окружение _python -m venv .venv_
2. Загрузить все необходимые зависимости с помощью _pip install -r requirements.txt_
3. Из папки, в которой лежит файл scrapy.cfg, запустить команду для старта парсинга _scrapy crawl <spider name>_. На аднный момент доступны пауки:
* regions - данные с форумов https://lizaalert.org/forum/viewforum.php?f=119 - запись происходит в result.json
* archive - данные с форума https://lizaalert.org/forum/viewforum.php?f=133 - запись происодит в result-2.json.

### Структура result.json

      {
       "Округ":{
           "Регион": {
               "ссылка на топик": {
                   "title":"",
                   "posts":[ <- тут будет список всех сообщений с форума для этого топика. Первое 99% описание потеряшки.
                      { 
                        "author":{
                            "username": "",
                            "profile_url": ""
                         },
                         "contents":[
                              "тут описание"
                         ],
                        "media": [
                              "тут ссылки на фотки из поста"
                         ],
                         "timestamp": "тут метка времени поста для подсчёта разницы между публикацией и пропажей"
                      },
                      ...
                   ]
               },
               ...
           },
           ...
       },
       ...
    }
      
